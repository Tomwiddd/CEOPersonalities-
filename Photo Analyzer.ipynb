{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33eb4726-4bed-4abd-b952-35c314423bcd",
   "metadata": {},
   "source": [
    "## Photo Analyzer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3296bcd8-39cc-4d92-9f0c-b9c218676d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'deepface.modules.modeling' has no attribute 'build_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Analyze image for all 4 attributes\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39manalyze(\n\u001b[1;32m      5\u001b[0m     img_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadshot.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# replace with your image path\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     actions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/deepface/DeepFace.py:253\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m(img_path, actions, enforce_detection, detector_backend, align, expand_percentage, silent, anti_spoofing)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze\u001b[39m(\n\u001b[1;32m    167\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    168\u001b[0m     actions: Union[\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    Analyze facial attributes such as age, gender, emotion, and race in the provided image.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m            - 'white': Confidence score for White ethnicity.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m demography\u001b[38;5;241m.\u001b[39manalyze(\n\u001b[1;32m    254\u001b[0m         img_path\u001b[38;5;241m=\u001b[39mimg_path,\n\u001b[1;32m    255\u001b[0m         actions\u001b[38;5;241m=\u001b[39mactions,\n\u001b[1;32m    256\u001b[0m         enforce_detection\u001b[38;5;241m=\u001b[39menforce_detection,\n\u001b[1;32m    257\u001b[0m         detector_backend\u001b[38;5;241m=\u001b[39mdetector_backend,\n\u001b[1;32m    258\u001b[0m         align\u001b[38;5;241m=\u001b[39malign,\n\u001b[1;32m    259\u001b[0m         expand_percentage\u001b[38;5;241m=\u001b[39mexpand_percentage,\n\u001b[1;32m    260\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    261\u001b[0m         anti_spoofing\u001b[38;5;241m=\u001b[39manti_spoofing,\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/deepface/modules/demography.py:123\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m(img_path, actions, enforce_detection, detector_backend, align, expand_percentage, silent, anti_spoofing)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[1;32m    121\u001b[0m resp_objects \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 123\u001b[0m img_objs \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mextract_faces(\n\u001b[1;32m    124\u001b[0m     img_path\u001b[38;5;241m=\u001b[39mimg_path,\n\u001b[1;32m    125\u001b[0m     detector_backend\u001b[38;5;241m=\u001b[39mdetector_backend,\n\u001b[1;32m    126\u001b[0m     enforce_detection\u001b[38;5;241m=\u001b[39menforce_detection,\n\u001b[1;32m    127\u001b[0m     grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m     align\u001b[38;5;241m=\u001b[39malign,\n\u001b[1;32m    129\u001b[0m     expand_percentage\u001b[38;5;241m=\u001b[39mexpand_percentage,\n\u001b[1;32m    130\u001b[0m     anti_spoofing\u001b[38;5;241m=\u001b[39manti_spoofing,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_obj \u001b[38;5;129;01min\u001b[39;00m img_objs:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m anti_spoofing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m img_obj\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_real\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/deepface/modules/detection.py:95\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img_path, detector_backend, enforce_detection, align, expand_percentage, grayscale, color_face, normalize_face, anti_spoofing)\u001b[0m\n\u001b[1;32m     93\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m [DetectedFace(img\u001b[38;5;241m=\u001b[39mimg, facial_area\u001b[38;5;241m=\u001b[39mbase_region, confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m detect_faces(\n\u001b[1;32m     96\u001b[0m         detector_backend\u001b[38;5;241m=\u001b[39mdetector_backend,\n\u001b[1;32m     97\u001b[0m         img\u001b[38;5;241m=\u001b[39mimg,\n\u001b[1;32m     98\u001b[0m         align\u001b[38;5;241m=\u001b[39malign,\n\u001b[1;32m     99\u001b[0m         expand_percentage\u001b[38;5;241m=\u001b[39mexpand_percentage,\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# in case of no face found\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m enforce_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/deepface/modules/detection.py:206\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(detector_backend, img, align, expand_percentage)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03mDetect face(s) from a given image\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    - confidence (float): The confidence score associated with the detected face.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 206\u001b[0m face_detector: Detector \u001b[38;5;241m=\u001b[39m modeling\u001b[38;5;241m.\u001b[39mbuild_model(\n\u001b[1;32m    207\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_detector\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39mdetector_backend\n\u001b[1;32m    208\u001b[0m )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# validate expand percentage score\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expand_percentage \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'deepface.modules.modeling' has no attribute 'build_model'"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "# Analyze image for all 4 attributes\n",
    "result = DeepFace.analyze(\n",
    "    img_path=\"headshot.jpg\",  # replace with your image path\n",
    "    actions=[\"age\", \"gender\", \"race\", \"emotion\"]\n",
    ")\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d0d49ca-1437-4783-a1ec-6b3d15372ede",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load image\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fer/__init__.py:27\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/python3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# SOFTWARE.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Video\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[1;32m     30\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fer/classes.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Union\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "from fer import FER\n",
    "import cv2\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(\"headshot.jpg\")\n",
    "\n",
    "# Initialize the FER detector\n",
    "detector = FER()\n",
    "\n",
    "# Analyze emotions\n",
    "emotion, score = detector.top_emotion(img)\n",
    "\n",
    "print(\"Emotion:\", emotion)\n",
    "print(\"Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4afdc9c-8288-48a6-91e8-4d6e651cfe14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
